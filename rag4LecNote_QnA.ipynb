{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Read PDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parsing PDF...\n",
      "Started parsing the file under job_id 79862f4f-8d82-4952-ac3d-3a1804148231\n",
      "Parsing complete.\n",
      "Total number of documents: 25\n"
     ]
    }
   ],
   "source": [
    "import nest_asyncio\n",
    "from llama_parse import LlamaParse\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Retrieve API key from environment variable\n",
    "os.environ[\"LLAMA_CLOUD_API_KEY\"] = os.getenv(\"LLAMA_CLOUD_API_KEY\")\n",
    "\n",
    "# Allow async event loop nesting (required in Jupyter or notebooks)\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Step 1: Load and parse PDF using LlamaParse\n",
    "parser = LlamaParse(result_type=\"markdown\")  # or \"text\" if you want plain output\n",
    "pdf_path = \"./data/Lecture1-a.pdf\"\n",
    "\n",
    "print(\"Parsing PDF...\")\n",
    "llama_parse_documents = parser.load_data(pdf_path)\n",
    "print(\"Parsing complete.\")\n",
    "\n",
    "# Step 2: Combine all parsed document texts into a single markdown string\n",
    "markdown_text = \"\\n\".join(doc.text for doc in llama_parse_documents)\n",
    "\n",
    "# Count the number of documents\n",
    "num_documents = len(llama_parse_documents)\n",
    "print(f\"Total number of documents: {num_documents}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Document 8 ---\n",
      "# Key Areas in DevOps\n",
      "\n",
      "- # Reduce Organizational Silos\n",
      "\n",
      "Everyone shares the ownership of production and information is shared among everyone.\n",
      "- # Accept Failure as Normal\n",
      "\n",
      "Blameless PMs/ RCA. Risk taking mindset.\n",
      "- # Implement Gradual Changes\n",
      "\n",
      "Frequent deployments, frequent deterministic releases in small chunks which can be rolled back.\n",
      "- # Leverage Tooling and Automation\n",
      "\n",
      "Automate and reduce manual work as much as possible.\n",
      "- # Measure Everything\n",
      "\n",
      "Application, systems monitoring and metrics etc...\n"
     ]
    }
   ],
   "source": [
    "# Display documents in a loop\n",
    "doc_number = 8\n",
    "if doc_number <= len(llama_parse_documents):\n",
    "    print(f\"--- Document {doc_number} ---\")\n",
    "    print(llama_parse_documents[doc_number - 1].text)\n",
    "else:\n",
    "    print(f\"Document {doc_number} does not exist. Total documents: {len(llama_parse_documents)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Split text into chunks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "✅ Total Chunks Created: 22\n"
     ]
    }
   ],
   "source": [
    "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
    "\n",
    "# Step 4: Split the parsed text into chunks\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
    "text_chunks = text_splitter.split_text(markdown_text)\n",
    "\n",
    "# Display info about chunks\n",
    "print(f\"\\n✅ Total Chunks Created: {len(text_chunks)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['# Intro to DevOps and Beyond\\n\\n# Ravindu Nirmal Fernando\\n# About Me\\n\\n- STL - DevOps @ Sysco LABS - Sri Lanka\\n- MSc in Computer Science specialized in Cloud Computing (UOM)\\n- AWS Certified Solutions Architect - Professional\\n- Certified Kubernetes Administrator (CKA)\\n- AWS Community Builder\\n\\nRavindu Nirmal Fernando\\n\\nhttps://ravindunfernando.com\\n# The Era before DevOps\\n# Developers\\n\\nFocused on Agility\\n\\n# Operators\\n\\nFocused on Stability\\n# Destructive downward spiral in IT\\n\\n# Act 01 - Operations teams',\n",
       " \"# Act 01 - Operations teams\\n\\nmaintaining large fragile applications\\n\\nDoesn't have any visibility on the application, whether or not its working as expected\\n\\n# Act 02 - The product managers\\n\\nLarger, unrealistic commitments made to the outside world (client/investors) without understanding the complexities behind development and operations\\n\\n# Act 03 - The Developers\\n\\nDevelopers taking shortcuts and putting more and more fragile code on top of existing ones\\n\\n# Act 04 - Dev and Ops at war\"]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print the first two chunks\n",
    "text_chunks[:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Embedding Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Education\\LearningAssistant-ChatBot\\.venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# huggingface embeddings models lot of them available there\n",
    "import torch\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "# Check if a GPU is available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model_name = \"BAAI/bge-small-en-v1.5\"\n",
    "# model_name = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "embedding_model = SentenceTransformer(model_name, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:14<00:00, 14.05s/it]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating embeddings...\")\n",
    "embeddings = embedding_model.encode(text_chunks, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(384,)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings[0].shape # store the embeddings in a list dimension"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Store in the Vector Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Successfully connected to Qdrant and retrieved collections.\n"
     ]
    }
   ],
   "source": [
    "# Import client library\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from qdrant_client import QdrantClient\n",
    "from qdrant_client.models import VectorParams, Distance\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Access environment variables\n",
    "qdrant_api_key = os.getenv(\"QDRANT_API_KEY\")\n",
    "\n",
    "\n",
    "\n",
    "# Connect to Qdrant using credentials from .env\n",
    "client = QdrantClient(\n",
    "    url=\"https://74fbf056-a412-4035-9c9b-b85d0055af43.us-west-1-0.aws.cloud.qdrant.io\",\n",
    "    api_key=qdrant_api_key,\n",
    ")\n",
    "\n",
    "try:\n",
    "    client.get_collections()\n",
    "    print(\"✅ Successfully connected to Qdrant and retrieved collections.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Connection failed: {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Delete Collection If already Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete the collection\n",
    "client.delete_collection(collection_name=\"qa_index\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create a collection in qdrant\n",
    "collection_name = \"qa_index\"\n",
    "client.delete_collection(collection_name)\n",
    "\n",
    "client.create_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors_config=VectorParams(size=384, distance=Distance.COSINE),# metrix is cosine for semantic similarity\n",
    "    \n",
    ")\n",
    "# demention of vector is 384\n",
    "# if return true collection is created we can stroe vectors in it\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Create payloads and ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'source': './data/Lecture1-a.pdf',\n",
       " 'content': '# Intro to DevOps and Beyond\\n\\n# Ravindu Nirmal Fernando\\n# About Me\\n\\n- STL - DevOps @ Sysco LABS - Sri Lanka\\n- MSc in Computer Science specialized in Cloud Computing (UOM)\\n- AWS Certified Solutions Architect - Professional\\n- Certified Kubernetes Administrator (CKA)\\n- AWS Community Builder\\n\\nRavindu Nirmal Fernando\\n\\nhttps://ravindunfernando.com\\n# The Era before DevOps\\n# Developers\\n\\nFocused on Agility\\n\\n# Operators\\n\\nFocused on Stability\\n# Destructive downward spiral in IT\\n\\n# Act 01 - Operations teams'}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ids = [] # list of ids for each vectors we can use to retrieve the vectors text chunks\n",
    "payload = [] # metadata for each vector we can use to retrieve the text chunks\n",
    "\n",
    "for id, text in enumerate(text_chunks):\n",
    "    ids.append(id)\n",
    "    payload.append({\"source\": pdf_path, \"content\": text})\n",
    "\n",
    "payload[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store the vectors in qdrant \n",
    "client.upload_collection(\n",
    "    collection_name=collection_name,\n",
    "    vectors=embeddings,\n",
    "    payload=payload,\n",
    "    ids=ids,\n",
    "    batch_size=256,  # How many vectors will be uploaded in a single request?\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CountResult(count=22)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count the number of vectors in the collection\n",
    "client.count(collection_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CollectionConfig(params=CollectionParams(vectors=VectorParams(size=384, distance=<Distance.COSINE: 'Cosine'>, hnsw_config=None, quantization_config=None, on_disk=None, datatype=None, multivector_config=None), shard_number=1, sharding_method=None, replication_factor=1, write_consistency_factor=1, read_fan_out_factor=None, on_disk_payload=True, sparse_vectors=None), hnsw_config=HnswConfig(m=16, ef_construct=100, full_scan_threshold=10000, max_indexing_threads=0, on_disk=False, payload_m=None), optimizer_config=OptimizersConfig(deleted_threshold=0.2, vacuum_min_vector_number=1000, default_segment_number=0, max_segment_size=None, memmap_threshold=None, indexing_threshold=20000, flush_interval_sec=5, max_optimization_threads=None), wal_config=WalConfig(wal_capacity_mb=32, wal_segments_ahead=0), quantization_config=None, strict_mode_config=StrictModeConfigOutput(enabled=True, max_query_limit=None, max_timeout=None, unindexed_filtering_retrieve=False, unindexed_filtering_update=False, search_max_hnsw_ef=None, search_allow_exact=None, search_max_oversampling=None, upsert_max_batchsize=None, max_collection_vector_size_bytes=None, read_rate_limit=None, write_rate_limit=None, max_collection_payload_size_bytes=None, max_points_count=None, filter_max_conditions=None, condition_max_size=None, multivector_config=None, sparse_config=None))"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check the distance metric in your Qdrant collection setup\n",
    "client.get_collection(collection_name).config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Retrieval Component"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search(text: str, top_k: int):# search for the text in the collection\n",
    "    query_embedding = embedding_model.encode(text).tolist()\n",
    "    \n",
    "    search_result = client.search(\n",
    "        collection_name=collection_name,\n",
    "        query_vector=query_embedding,\n",
    "        query_filter=None,  \n",
    "        limit=top_k\n",
    "    )\n",
    "    return search_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishwa\\AppData\\Local\\Temp\\ipykernel_524\\853163018.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = client.search(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ScoredPoint(id=2, version=0, score=0.83806455, payload={'source': './data/Lecture1-a.pdf', 'content': '# Act 04 - Dev and Ops at war\\n\\n\"It worked on my machine\" phenomenon\\n# How can we overcome these issues?\\n# What is DevOps?\\n\\n“DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity” - What is DevOps? [AWS]\\n\\n“A compound of development (Dev) and operations (Ops), DevOps is the union of people, process, and technology to continually provide value to customers.” - What is DevOps? [Azure]'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=3, version=0, score=0.79262567, payload={'source': './data/Lecture1-a.pdf', 'content': 'DevOps allows evolving and improving products at a faster pace than businesses using traditional software development and infrastructure management processes. This speed allows businesses to serve their customers better and compete effectively.\\n# Key Areas in DevOps\\n\\n- # Reduce Organizational Silos\\n\\nEveryone shares the ownership of production and information is shared among everyone.\\n- # Accept Failure as Normal\\n\\nBlameless PMs/ RCA. Risk taking mindset.\\n- # Implement Gradual Changes'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=16, version=0, score=0.7155807, payload={'source': './data/Lecture1-a.pdf', 'content': '- Not competing with DevOps\\n- Think that Class SRE implements Interface DevOps\\n- SRE is a part of the DevOps umbrella\\n\\n# SRE Practices\\n\\n- Identify and measure SLIs, define SLOs and agree/commit to SLA for product and service\\n- Chaos Engineering\\n- Removing toil\\n- System designing (DR, Multi-Region, Multi-Cloud)\\n- Postmortems/ Root Cause Analysis\\n- Observability\\n# Platform Engineering\\n\\nBefore jumping to definition, let’s understand the problem…'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=9, version=0, score=0.7113116, payload={'source': './data/Lecture1-a.pdf', 'content': '# Cloud Infrastructure\\n\\nCloud provides more flexibility, scalability and toolsets for organizations to implement DevOps culture and practices. Serverless architecture in cloud brings down the efforts of DevOps teams as it eliminates server management operations.\\n\\n# Continuous Monitoring, Logging and Alerting'}, vector=None, shard_key=None, order_value=None),\n",
       " ScoredPoint(id=19, version=0, score=0.70254976, payload={'source': './data/Lecture1-a.pdf', 'content': '# Components\\n\\n# Consumption\\n\\n# Direction\\n\\n|X-as-a-Service|Developer Portal| | |\\n|---|---|---|---|\\n|Reusable Components|Tools|Platform|Knowledge|\\n|Digital Platform| | | |\\n| |Team(s)| | |\\n|Infrastructure Platform| | | |\\n|Infrastructure Complexity| | | |\\n\\nSource: Gartner\\n\\n2023 Gartner; Inc. and its affiliates. All rights reserved. CM_GTS_2479487\\n# Carrier as a DevOps Engineer\\n# DevOps Engineer Role'}, vector=None, shard_key=None, order_value=None)]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "question = \"what is devops?\"\n",
    "results = search(question, top_k=5) # retrieve the top 5 most similar vectors form the query\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'# Act 04 - Dev and Ops at war\\n\\n\"It worked on my machine\" phenomenon\\n# How can we overcome these issues?\\n# What is DevOps?\\n\\n“DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity” - What is DevOps? [AWS]\\n\\n“A compound of development (Dev) and operations (Ops), DevOps is the union of people, process, and technology to continually provide value to customers.” - What is DevOps? [Azure]'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_chunks[2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Response Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = \"\"\"You are an ai assistant for question-answering tasks. Answer the question according only to the given context.\n",
    "If question cannot be answered using the context, simply say I don't know. Do not make stuff up.\n",
    "\n",
    "Context: {context}\n",
    "\"\"\"\n",
    "\n",
    "user_prompt = \"\"\"\n",
    "Question: {question}\n",
    "\n",
    "Answer:\"\"\"\n",
    "\n",
    "references = [obj.payload[\"content\"] for obj in results]\n",
    "\n",
    "\n",
    "context = \"\\n\\n\".join(references)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Response with References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RAG (Retrieval-Augmented Generation) principles: discourage hallucinations, only answer from the given documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "DevOps is a set of practices that aim to automate and integrate the processes between software development and IT operations teams. It focuses on collaboration, continuous improvement, and rapid innovation.\n",
      "\n",
      "REFERENCES:\n",
      "\n",
      "Reference [1]: # X (Twitter)\n",
      "\n",
      "@ravindunf\n",
      "\n",
      "# SCAN ME\n",
      "\n",
      "Thank You!\n",
      "\n",
      "Reference [2]: |VisualStucio|Sonatype|Z-PHYR|BrowserStack|Team Fourdation Server|freshdesk| | | |\n",
      "| | |OMETR|Inse0n|OmnidESK|[:]|SoucceCleac| | |\n",
      "\n",
      "Reference [3]: |zoominfo| | |0| | | | | |\n",
      "|pagerduty|VtorOps|matters|1|Blueleans| | | | |\n",
      "|slack 1|~BUILD| |New Relic| | | | | |\n",
      "|snyk|CODE CLIMATE|git|GitLab|CONTINUOUS| | | | |\n",
      "| | | |OPERATE|bugsnag|Nagios|splunk|>|GGLY|\n",
      "|IFrog|Mpm|FitNesse|SAUCELABS|servicenuw|TestFairy| | | |\n",
      "|9RAYCUN|ZABBIX|docker|GitHub|dc|runnable| | | |\n",
      "| | |zendesk|Jasmine|SENTRY|DATADOG|blopunca|dvnatece| |\n",
      "|kubernetes| |HATEACOM|@u CRM|cucumber|Rollbar|APPDYNAMICS| | |\n",
      "\n",
      "Reference [4]: |asana|PivotalTracker|Teamcity|shippable|(WHashiCorp|amazon| | | |\n",
      "|---|---|---|---|---|---|---|---|---|\n",
      "|drv.i0 boX|Lucidchart|Jenkins|Travis Cl|Micrasit|flowdock| | | |\n",
      "| |planio|CODE $ AIP|buddybuild|circlecl|Googk Cloaeuttonn|Azure| | |\n",
      "|Drte|Wrike| |RELEASE| | | | | |\n",
      "|Googl? E| |split|Office Goog - Docs|DEFLOY| | | | |\n",
      "|smartsheel|gliffy| |DEPLOY|puppet| | | | |\n",
      "|CHEF|Basecamp|(|PLAN| | | | | |\n",
      "|@Trello| |1 INTEGRATION|m|OpsGenie| | | | |\n",
      "|zoominfo| | |0| | | | | |\n",
      "\n",
      "Reference [5]: # Components\n",
      "\n",
      "# Consumption\n",
      "\n",
      "# Direction\n",
      "\n",
      "|X-as-a-Service|Developer Portal| | |\n",
      "|---|---|---|---|\n",
      "|Reusable Components|Tools|Platform|Knowledge|\n",
      "|Digital Platform| | | |\n",
      "| |Team(s)| | |\n",
      "|Infrastructure Platform| | | |\n",
      "|Infrastructure Complexity| | | |\n",
      "\n",
      "Source: Gartner\n",
      "\n",
      "2023 Gartner; Inc. and its affiliates. All rights reserved. CM_GTS_2479487\n",
      "# Carrier as a DevOps Engineer\n",
      "# DevOps Engineer Role\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "# 1. Format prompt\n",
    "final_prompt = system_prompt.format(context=context) + user_prompt.format(question=question)\n",
    "\n",
    "# 2. API URL for completion mode\n",
    "api_url = \"http://localhost:11434/api/generate\"\n",
    "\n",
    "# 3. Payload\n",
    "payload = {\n",
    "    \"model\": \"gemma3:1b\",\n",
    "    \"prompt\": final_prompt,\n",
    "    \"stream\": True,\n",
    "    \"temperature\": 0.1\n",
    "}\n",
    "\n",
    "# 4. Send request\n",
    "response = requests.post(api_url, json=payload, stream=True)\n",
    "\n",
    "# 5. Read streamed chunks and build the answer\n",
    "print(\"\\n\\nANSWER:\\n\")\n",
    "full_answer = \"\"\n",
    "\n",
    "if response.status_code == 200:\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            data = line.decode('utf-8')\n",
    "            chunk = json.loads(data)\n",
    "            if 'response' in chunk:\n",
    "                token = chunk['response']\n",
    "                full_answer += token\n",
    "                print(token, end='', flush=True)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# 6. After streaming is done, print references\n",
    "print(\"\\n\\nREFERENCES:\\n\")\n",
    "for index, ref in enumerate(references):\n",
    "    cleaned_ref = ref.strip()\n",
    "    if cleaned_ref:\n",
    "        print(f\"Reference [{index + 1}]: {cleaned_ref}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Vishwa\\AppData\\Local\\Temp\\ipykernel_524\\853163018.py:4: DeprecationWarning: `search` method is deprecated and will be removed in the future. Use `query_points` instead.\n",
      "  search_result = client.search(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "ANSWER:\n",
      "\n",
      "- Reduce Organizational Silos\n",
      "- Accept Failure as Normal\n",
      "- Implement Gradual Changes\n",
      "- Leverage Tooling and Automation\n",
      "- Measure Everything\n",
      "\n",
      "REFERENCES:\n",
      "\n",
      "Reference [1]: DevOps allows evolving and improving products at a faster pace than businesses using traditional software development and infrastructure management processes. This speed allows businesses to serve their customers better and compete effectively.\n",
      "# Key Areas in DevOps\n",
      "\n",
      "- # Reduce Organizational Silos\n",
      "\n",
      "Everyone shares the ownership of production and information is shared among everyone.\n",
      "- # Accept Failure as Normal\n",
      "\n",
      "Blameless PMs/ RCA. Risk taking mindset.\n",
      "- # Implement Gradual Changes\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Reference [2]: # Act 04 - Dev and Ops at war\n",
      "\n",
      "\"It worked on my machine\" phenomenon\n",
      "# How can we overcome these issues?\n",
      "# What is DevOps?\n",
      "\n",
      "“DevOps is the combination of cultural philosophies, practices, and tools that increases an organization’s ability to deliver applications and services at high velocity” - What is DevOps? [AWS]\n",
      "\n",
      "“A compound of development (Dev) and operations (Ops), DevOps is the union of people, process, and technology to continually provide value to customers.” - What is DevOps? [Azure]\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Reference [3]: Frequent deployments, frequent deterministic releases in small chunks which can be rolled back.\n",
      "- # Leverage Tooling and Automation\n",
      "\n",
      "Automate and reduce manual work as much as possible.\n",
      "- # Measure Everything\n",
      "\n",
      "Application, systems monitoring and metrics etc...\n",
      "DevOps\n",
      "Practices\n",
      "# Continuous Integration (CI)\n",
      "\n",
      "Software development practice where developers regularly merge their code changes into a central repository, after which automated builds and tests are run.\n",
      "\n",
      "# Continuous Delivery (CD)\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Reference [4]: # Components\n",
      "\n",
      "# Consumption\n",
      "\n",
      "# Direction\n",
      "\n",
      "|X-as-a-Service|Developer Portal| | |\n",
      "|---|---|---|---|\n",
      "|Reusable Components|Tools|Platform|Knowledge|\n",
      "|Digital Platform| | | |\n",
      "| |Team(s)| | |\n",
      "|Infrastructure Platform| | | |\n",
      "|Infrastructure Complexity| | | |\n",
      "\n",
      "Source: Gartner\n",
      "\n",
      "2023 Gartner; Inc. and its affiliates. All rights reserved. CM_GTS_2479487\n",
      "# Carrier as a DevOps Engineer\n",
      "# DevOps Engineer Role\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Reference [5]: # Cloud Infrastructure\n",
      "\n",
      "Cloud provides more flexibility, scalability and toolsets for organizations to implement DevOps culture and practices. Serverless architecture in cloud brings down the efforts of DevOps teams as it eliminates server management operations.\n",
      "\n",
      "# Continuous Monitoring, Logging and Alerting\n",
      "--------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ✅ Self-contained test cell: enter question and run everything fresh\n",
    "\n",
    "# 1. Input your question here\n",
    "question = \"what are the key areas in devops?\"\n",
    "\n",
    "# 2. Rerun semantic search to get most relevant chunks\n",
    "results = search(question, top_k=5)\n",
    "references = [obj.payload[\"content\"] for obj in results]\n",
    "context = \"\\n\\n\".join(references)\n",
    "\n",
    "# 3. Format prompt\n",
    "final_prompt = system_prompt.format(context=context) + user_prompt.format(question=question)\n",
    "\n",
    "# 4. Build payload and send request\n",
    "payload = {\n",
    "    \"model\": \"gemma3:1b\",\n",
    "    \"prompt\": final_prompt,\n",
    "    \"stream\": True,\n",
    "    \"temperature\": 0.1\n",
    "}\n",
    "\n",
    "response = requests.post(api_url, json=payload, stream=True)\n",
    "\n",
    "# 5. Stream and display answer\n",
    "print(\"\\n\\nANSWER:\\n\")\n",
    "full_answer = \"\"\n",
    "\n",
    "if response.status_code == 200:\n",
    "    for line in response.iter_lines():\n",
    "        if line:\n",
    "            data = line.decode('utf-8')\n",
    "            chunk = json.loads(data)\n",
    "            if 'response' in chunk:\n",
    "                token = chunk['response']\n",
    "                full_answer += token\n",
    "                print(token, end='', flush=True)\n",
    "else:\n",
    "    print(f\"Error: {response.status_code} - {response.text}\")\n",
    "\n",
    "# 6. Show references used\n",
    "print(\"\\n\\nREFERENCES:\\n\")\n",
    "for index, ref in enumerate(references):\n",
    "    cleaned_ref = ref.strip()\n",
    "    if cleaned_ref:\n",
    "        print(f\"Reference [{index + 1}]: {cleaned_ref}\\n{'-' * 80}\\n\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
